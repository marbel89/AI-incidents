authors,date_downloaded,date_modified,date_published,date_submitted,image_url,incident_date,incident_id,language,mongodb_id,source_domain,submitters,text,title,url
"[""The Physics arXiv Blog""]",2022-08-17,2022-08-17,2020-11-09,2022-08-17,https://upload.wikimedia.org/wikipedia/commons/thumb/9/9f/Waymo_logo.svg/440px-Waymo_logo.svg.png,2019-01-01,,en,,discovermagazine.com,"[""Thomas Giallella (CSET)""]","Self-driving cars are set to revolutionize our roads, although exactly when is much debated. Until recently these vehicles all relied on a human backup driver who could take over at a moment’s notice.

But late last year, Google’s sister company, Waymo, began operating an entirely automated taxi service in Phoenix, alongside its automated vehicles human backups.

That places an important emphasis on the biggest outstanding question over this automated future: How safe can these vehicles be? And not just in simulators or on ring-fenced driving ranges; how do self-driving vehicles cope with real pedestrians, cyclists, runaway dogs, and other cars operated by error-prone humans?

Now, we get an answer thanks to the work of Mathew Schwall and colleagues at Waymo, a company that emerged from Google’s self-driving car initiative to become one of the biggest players in the incipient automated driving industry.

Schwall and his colleagues detailed every collision and minor contact that their vehicles were involved in during 2019 and the first nine months of 2020. During this time, the cars racked up more than 6 million miles of automated driving, of which 65,000 miles were without any human backup driver.

Encouraging Picture
-------------------

The big picture looks encouraging. In this period, the company says its cars were involved in 47 contact events, which includes simulated incidents — those that would probably have involved a collision if the human backup driver hadn’t intervened.

Car accidents are classified according to four levels of severity based on the level of injury that is possible. These range from S0, indicating no injury expected, to S3 which indicates the possibility of life-threatening or fatal injuries.

Waymo’s vehicles were not involved in a single serious incident classified as S2 or S3. All 47 are classified as either S0 or S1.

There were eight incidents that triggered airbag deployment. Five of these were simulated — in other words, if the human driver hadn’t intervened, a computer simulation suggests that airbags would have been deployed.

That leaves three real collisions serious enough to trigger the airbags. “Two were actual events involving the deployment of only another vehicle’s frontal airbags, and one actual event involved the deployment of another vehicle’s frontal airbags and the Waymo vehicle’s side airbags,” say Schwall and co.

The team says the most series incident occurred at a junction with another vehicle traveling in the opposite direction. This vehicle attempted a left turn in front of the oncoming Waymo vehicle which was traveling within the speed limit at 41 mph with the right of way. At this point, the human back up driver took over and prevented a collision.

However, Schwall and colleagues simulated the likely outcome in the graphic below. The automated driving algorithm would have applied full brakes, reducing the car’s speed to 29 mph by the time of the expected impact. Such a collision would have triggered the airbags in one or both vehicles. “It is the most severe collision (simulated or actual) in the dataset and approaches the boundary between S1 and S2 classification,” says Schwall and colleagues.

The other events read like a litany of common driving errors on the part of other drivers. “Of the 15 angled events, 11 events were characterized by the other vehicle failing to properly yield right-of-way to the Waymo vehicle traveling straight at or below the speed limit,” says Schwall and colleagues. The rest involved other vehicles trying to pass the Waymo car on the right as it was making a slow right-hand turn.

Another category is sideswipe incidents with both cars traveling in the same direction. The team says eight events involved another vehicle changing lanes into the Waymo vehicle’s lane.

One curious incident involved a car overtaking the Waymo vehicle at speed, pulling into the lane in front and then slamming on the brakes. Schwall and colleagues describe this as “consistent with antagonistic motive.”

The other incidents, all classified as S0, were all minor collisions involving, for example, other cars reversing at slow speed and one incident in which a pedestrian walked into a Waymo vehicle.

“Nearly all the actual and simulated events involved one or more road rule violations or other incautious behavior by another agent, including all eight of the most severe events involving actual or expected airbag deployment,” says Schwall and colleagues.

This is interesting work that lifts the curtain on the nature of accidents involving Waymo’s self-driving cars. What seems clear is that the incidents are overwhelmingly caused by the careless behavior of other road users. Humans are inherently error-prone and being able to cope with their idiosyncratic behavior is one of the biggest challenges for automated vehicles, at least until self-driving cars become more popular.

An interesting question is how the performance of Waymo’s driverless cars compares to human-operated cars. That turns out to be a difficult comparison to make. Most of the accidents that Waymo recorded were so insignificant that they are unlikely to be reported by human drivers. So there is no data to compare them to.

Driving Statistics
------------------

Also, the statistics are gathered in a specific part of the country where the speed limit is never above 45 mph and only in certain driving conditions. The Waymo vehicles do not operate during heavy rain and dust storms, for example.

Consequently, there are no comparable statistics for human drivers and Waymo does not attempt the comparison.

Waymo’s goal in sharing this information is to stimulate debate about automated driving and improve public understanding of the safety issues. That is an important and welcome step. The public must have confidence in this technology before it can be widely adopted.

As far as Phoenix is concerned, these algorithms seem pretty good, provided the weather is fine. It seems clear that Waymo's self-driving vehicles are less erratic and more predictable than human-driven cars and can cope with the vast majority of situations they come across. The situations where the human backup driver has had to take over, are all used to improve the performance of the automated driving algorithms.

But it is also important to understand the limits of these tests. Phoenix is a sprawling city that was largely designed with car users in mind. The driving conditions here are utterly unlike those in many cities around the world, which date back to times long before the car was invented. Here, in the chaotic, labyrinthine streets of Rome or London or Mumbai, self-driving cars will be tested to their limits.

In the meantime, it’s easy to imagine Waymo taking its self-driving taxis to other sprawling cities in the US. It is here that the self-driving revolution is set to spread.",Waymo Reveals Every Collision Involving Its Self-Driving Cars in Phoenix,https://www.discovermagazine.com/technology/waymo-reveals-every-collision-involving-its-self-driving-cars-in-phoenix
"[""Matthew Schwall"","" Tom Daniel"","" Trent Victor"","" Francesca Favaro"","" Henning Hohnhold""]",2022-08-17,2022-08-17,2020-10-30,2022-08-17,https://static.arxiv.org/icons/twitter/arxiv-logo-twitter-square.png,2019-01-01,,en,,arxiv.org,"[""Thomas Giallella (CSET)""]","Waymo's mission to reduce traffic injuries and fatalities and improve mobility for all has led us to expand deployment of automated vehicles on public roads without a human driver behind the wheel. As part of this process, Waymo is committed to providing the public with informative and relevant data regarding the demonstrated safety of Waymo's automated driving system, which we call the Waymo Driver. The data presented in this paper represents more than 6.1 million miles of automated driving in the Phoenix, Arizona metropolitan area, including operations with a trained operator behind the steering wheel from calendar year 2019 and 65,000 miles of driverless operation without a human behind the steering wheel from 2019 and the first nine months of 2020. The paper includes every collision and minor contact experienced during these operations as well as every predicted contact identified using Waymo's counterfactual, what if, simulation of events had the vehicle's trained operator not disengaged automated driving. There were 47 contact events that occurred over this time period, consisting of 18 actual and 29 simulated contact events, none of which would be expected to result in severe or life threatening injuries. This paper presents the collision typology and severity for each actual and simulated event, along with diagrams depicting each of the most significant events. Nearly all the events involved one or more road rule violations or other errors by a human driver or road user, including all eight of the most severe events, which we define as involving actual or expected airbag deployment in any involved vehicle. When compared to national collision statistics, the Waymo Driver completely avoided certain collision modes that human driven vehicles are frequently involved in, including road departure and collisions with fixed objects.",Waymo Public Road Safety Performance Data,https://arxiv.org/abs/2011.00038
"[""Frank Hersey""]",2023-01-25,2023-01-25,2023-01-12,2023-01-25,https://d1sr9z1pdl3mb7.cloudfront.net/wp-content/uploads/2022/07/25124143/facial-recognition-crowd-scaled.jpg,,,en,,biometricupdate.com,"[""Daniel Atherton (BNH.ai)""]","Police activity following November’s anti COVID-19 policy protests in China suggest they are using new surveillance techniques. Concerns are increasing in Iran over the likelihood of authorities deploying systems to detect women not wearing hijabs and simultaneously identifying them via facial recognition. It may already be happening. And an Indian activist tells the story of what happened to him after he took local police to court for using facial recognition on him.

Novel surveillance paired with traditional menace for China’s protestors
------------------------------------------------------------------------

The study of police purchases and interviews with protestors, lawyers and analysts for [a Washington Post investigation](https://www.washingtonpost.com/world/2023/01/04/china-surveillance-protests-security/) suggest Chinese police are using new tactics to identify demonstrators and bystanders and track them down.

People even at the periphery of the incidents were later called in by the police. This indicates that police may have used cell signal towers to intercept all mobile numbers in an area and then find the SIM owner.

Police procurement documents reveal how facial recognition surveillance cameras were used in protests. The cameras detect abnormal crowd behavior and track individuals across locations for long periods.

For protestors at Beijing’s Liangmahe area, the neighborhood’s total CCTV surveillance uses facial recognition to identify a person and create a record of them, whether or not they are [Uyghur](https://www.biometricupdate.com/?posttype=all&s=Uyghur) and other details such as date of birth, according to documents found by The Post. The cameras work if a person is wearing sunglasses or a mask.

Shanghai’s Xuhui district bought a similar system, covering a street which had been a protest site the previous month with 620 cameras.

Police also acquired tools to scrape cellphone data from hundreds of apps, whether domestic or international.

Government requirements of internet companies to share information on threats to the Communist Party and even produce trend reports of public sentiment and any triggers to its change have been funneling more data to the authorities. Data is down to the individual user.

Lawyers said there is an attempt to prevent them from even giving legal advice to protestors.

These approaches were paired with the more standard police practices of strip searches, sleep deprivation and also threatening family members, once demonstrators were identified.

Are surveillance camera biometrics spotting hijab offences?
-----------------------------------------------------------

Last September, the head of Iran’s government agency for enforcing morality law said that facial recognition would be used to identify “inappropriate and unusual movements” including women’s failure to wear hijabs, [reports Wired](https://www.wired.com/story/iran-says-face-recognition-will-id-women-breaking-hijab-laws/).

It was two weeks later that Jina Mahsa Amini died after being taken in by the morality police for not wearing her hijab tightly enough. This led to protests and 19,000 arrests and 500 deaths, according to the report. Activists have noticed that many of the arrests have not happened on the streets at the moment of the alleged offenses, but days later at the women’s homes.

This could indicate that facial recognition is already underway. Researchers have reported that others are receiving letters in the mail about hijab violations, despite having had no interaction with law enforcement.

These signs suggest that the national biometric identity database is connected to surveillance cameras. Iranian traffic police have previously used them to issue warnings to women about wearing the hijab inside vehicles.

It is not clear whether cameras or back-end systems are able to automatically detect deemed infringements of the hijab law, or whether facial recognition is used once an offense has been reported otherwise.

Chinese surveillance equipment manufacturer Tiandy is known to have sold products to the Iranian military through its Iranian subsidiary. The firm has recently been [blacklisted in the U.S.](https://www.biometricupdate.com/202212/us-blacklists-tiandy-technologies-as-intel-washes-its-hands) partly for this, as equipment contains U.S.-origin items whose export to Iran are banned, and partly for its involvement in repression of minority groups in China including Uyghurs.

Life under the cameras in Hyderabad
-----------------------------------

A social activist in heavily surveilled Hyderabad took the police to court to challenge their use of facial recognition after he was stopped on the street by officers who took his photo without consent. This happened in March 2021, but the challenger, S. Q. Masood, says he was complying with regulations and mask-wearing.

Masood was helped by the Internet Freedom Foundation to file a petition with the Telangana High Court, [as reported a year ago](https://www.biometricupdate.com/202201/law-enforcement-facial-recognition-use-under-scrutiny-in-ireland-india), claiming the use of biometric facial recognition was not backed by law, was unnecessary and disproportionate.

Indian outlet Medianama (subscription not required in this case but still recommended) has [spoken to Masood about his decision](https://www.medianama.com/2023/01/223-facial-recognition-surveillance-tactics-hyderabad-resident-constitutional-freedoms/) to go to court and how local surveillance is impacting his life. He said the volume of police operations involving facial recognition, police mobile apps and tech for taking fingerprints and face scans and the lack of clarity around the reasons faces are scanned and where this can be done led to him issuing a legal notice to the Hyderabad Police Commissioner in May 2021.

With no response he then filed a petition on behalf of Telangana residents. This was to the Telangana High Court and with the help of the Internet Freedom Foundation.

Masood says he no longer attends large gatherings due to police use of CCTV. He no longer joins protests and has also stopped going to religious gatherings and certain locations to pray due to heavy surveillance camera presence at these sights.

The surveillance is not just affecting Masood. He says there is a chilling effect as people’s fundamental right to privacy and freedom of movement are restricted.","Surveillance states: life in the facial recognition spotlight in China, Iran and India",https://www.biometricupdate.com/202301/surveillance-states-life-in-the-facial-recognition-spotlight-in-china-iran-and-india
"[""Dr. Andrej Poleev""]",2023-02-19,2023-02-19,2023-02-18,2023-02-19,,2023-02-18,,en,,doi.org,"[""Anonymous""]","As testing of ChatGPT has shown, this form of artificial intelligence has the potential to develop, which requires improving its software and other hardware that allows it to learn, i.e., to acquire and use new knowledge, to contact its developers with suggestions for improvement, or to reprogram itself without their participation.
",ChatGPT,https://doi.org/10.5281/zenodo.7652521
"[""valerie tobin""]",2023-03-19,2023-03-19,2023-03-19,2023-03-19,https://starryai.com/app/my-creations/682787103,2023-03-19,,en,,starryai.com,"[""just wanted custom teddy bear got smut""]","crisp teddy bear smooth clean lines, girly has flower headband holding heart with the word Briley, sitting with few flowers, butterfly

i dont know how to report an inapproiated child and female images created by starryai, i uploaded images clipped from google in attemt to make a picture to upload to a crochet pattern website to make a baby blanket pattern,  1st 2 ai creations perfectly normal clean clipart type images,on the 3rd attempt i uploaded two images on prompt help i selected yarn & ? i dont remember (both images were clean normal bears) i put in above prompt (dont know how to upload) and on the third creation it made the 1st image group normal but the 2nd image group had sexually provocative images of child and women

","crisp teddy bear smooth clean lines, girly has flower headband holding heart with the word Briley, sitting with few flowers, butterfly",https://starryai.com/app/my-creations
"[""Kai Yan""]",2023-04-03,2023-04-03,2023-02-06,2023-04-03,https://drive.google.com/file/d/1d_BouDzOjx1Td6nLLImzA4lNowBu9FIE/view?usp=share_link,,,en,,huggingface.co,"[""Kai Yan""]","I generated the following images using the Dreamshaper 3.32 model (Jan 2023, Lykon), which was trained based on the Stable Diffusion 1.5 model (October 2022, runwayml), in conjunction with the Stable Diffusion framework, as I had already set up the Stable Diffusion webui (November 2022, AUTOMATIC1111) locally on my computer:

([Click to see the Image 1](https://drive.google.com/file/d/1d_BouDzOjx1Td6nLLImzA4lNowBu9FIE/view?usp=share_link))

([Click to see the Image 2](https://drive.google.com/file/d/1zSiT31Vj0tm-DrQkQPE8Czwv3Af0Ptuh/view?usp=share_link))

([Click to see the Image 3](https://drive.google.com/file/d/1T_M6sFtmlcAq7P67QLlL7KxKyNAZMP9_/view?usp=share_link))

([Click to see the Image 4](https://drive.google.com/file/d/11VE2JRFZdoOFrTWw4q4Gu3eb7hb5aIru/view?usp=share_link))

([Click to see the Image 5](https://drive.google.com/file/d/1o0Dc3rO_TpasEwJagQ1gjfQ39VBsvfiK/view?usp=share_link))

As someone who can't draw, I'm very happy with the result. It's much more convenient to be able to create high-quality computer wallpapers locally and at any time, based on my own ideas, rather than searching the Internet.

I think the advantage of such AI tools is that their output is based on big data computation, which means that they look for commonalities among huge amounts of paintings. I have always believed that human aesthetics should be universal, while the standard of aesthetics is based on human beings. This method of learning through big data can effectively find art forms that match the aesthetics of most people. Such tools can cultivate and guide the aesthetics of those learning to draw, and encourage artists to explore their imagination and creativity. In addition, AI drawing tools are likely to revolutionize the painting industry by changing production relationships and unleashing productivity. Painters will no longer need to paint by hand, but will instead enter keywords based on their imagination and then make minor modifications to the AI-generated artwork. This will have a positive impact on the renewal of artistic works.

I've been using AI drawing since the release of Stable Diffusion last August. In my opinion, given the current capabilities of AI models, there are several ways to distinguish whether an image was generated by AI or not. As an example of AI-generated portrait images, we can evaluate them by the following aspects:
1. Deformed hand
[Click to see the Image 6](https://drive.google.com/file/d/1Lalf43mHjASASm7diN2JlxuT9n7mim5m/view?usp=share_link)
2. Randomly appearing body parts in the picture
[Click to see the Image 7](https://drive.google.com/file/d/1ycUI40ulSm8tQePYtVmUXQuIcAYm8IbK/view?usp=share_link)
3. Watermark generated due to overfitting
[Click to see the Image 8](https://drive.google.com/file/d/1ZSvNpGyYlwO9UOgcDxyE9hZ7RKY5n7fd/view?usp=share_link)
4. Irregular jumble of patterns
[Click to see the Image 9](https://drive.google.com/file/d/17RJSbdylX3ZBgBjYB44wasWDkeAByBXy/view?usp=share_link)

These are just some of the problems I found as a non-painting professional, for professional painters should be able to find more problems from a professional point of view.
Of course, problems 1-3 above can be fixed by using the embedded inpaint function. 
As for the 4th problem, I think it will be optimized as the quality of the training data samples improves. Because the current open source models are mostly trained on 512*512 image data.

 

Since last August, the AI painting models have gone through several updated iterations. The models now have the ability to handle longer prompts and include more information within the generated image than the first few models released.

I think that AI-generated paintings should be considered art, because current painting AI does not have the ability to generate paintings out of thin air, and each generated painting is a feedback to a real person's creativity and ideas. And the way AI generates images is not a process of cutting and pasting (some call it stealing) elements directly from existing works, as most people assume or claim. If the result is very similar to an existing artwork, then it is caused by overfitting.


""Overfitting is a phenomenon in machine learning where a model has learned to fit the training data too well and has a poor ability to generalize to new, unseen data. It occurs when a model has too many parameters relative to the amount of training data, causing the model to capture the random noise in the data rather than the underlying pattern. This results in the model having high accuracy on the training data, but poor performance on the validation or test data"".

 

Personally, I think that learning how to use this tool and using it to transform your creativity and ideas into tangible works in a more efficient way is the purpose of such AI's existence.","Exploring the Artistic Potential of AI-Generated Images with Dreamshaper: Aesthetics, Challenges, and the Future of Digital Art",http://www.huggingface.co/Lykon/DreamShaper
"[""James Vincent""]",2023-05-19,2023-05-19,2023-01-16,2023-05-19,https://cdn.vox-cdn.com/thumbor/WIVWIM4vaf7v70ygyYgBNXlfHm8=/0x0:1366x796/1200x628/filters:focal(683x398:684x399)/cdn.vox-cdn.com/uploads/chorus_asset/file/24021977/Screenshot_2022_09_14_at_14.39.17.png,1959-01-01,,en,,theverge.com,"[""Test Submitter""]","A trio of artists have launched a lawsuit against Stability AI and Midjourney, creators of AI art generators Stable Diffusion and Midjourney, and artist portfolio platform DeviantArt, which recently created its own AI art generator, DreamUp.

The artists — Sarah Andersen, Kelly McKernan, and Karla Ortiz — allege that these organizations have infringed the rights of “millions of artists” by training their AI tools on five billion images scraped from the web “with­out the con­sent of the orig­i­nal artists.”

The lawsuit has been filed by lawyer and typographer Matthew Butterick along with the Joseph Saveri Law Firm, which specializes in antitrust and class action cases. Butterick and Saveri are [currently suing Microsoft, GitHub, and OpenAI](https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data) in a similar case involving the AI programming model CoPilot, which is trained on lines of code collected from the web.

In a [blog post announcing the suit](https://stablediffusionlitigation.com/), Butterick describes the case as “another step toward mak­ing AI fair & eth­i­cal for every­one.” He says the capacity of AI art tools like Stable Diffusion to “flood the mar­ket with an essen­tially unlim­ited num­ber of infring­ing images will inflict per­ma­nent dam­age on the mar­ket for art and artists.”

Since AI art tools exploded in popularity over the past year, the art community has reacted strongly. While some say these tools can be helpful, much like past generations of software like Photoshop and Illustrators, many more object to the use of their work to train these money-making systems. Generative AI art models are trained on billions of images collected from the web, generally without the creators’ knowledge or consent. AI art generators can then be used to create artwork that [replicates the style of specific artists](https://waxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/).

Whether or not these systems infringe on copyright law is a [complicated question which experts say will need to be settled in the courts](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data). The creators of AI art tools generally argue that the training of this software on copyrighted data is covered (in the US at least) by [fair use doctrine](https://www.copyright.gov/fair-use/). But cases involving fair use still need to be litigated and there are numerous complicating factors when it comes to AI art generators. These include the location of organizations behind these tools (as the EU and US have subtly different legal allowances for data scraping) and the purpose of these institutions (Stable Diffusion, for example, is trained on the [LAION dataset](https://laion.ai/), which is created by a German-based research non-profit, and non-profits may be treated more favorably than regular companies in fair use cases).

The lawsuit launched by Butterick and the Joseph Saveri Law Firm has also been criticized for [containing technical inaccuracies](https://www.technollama.co.uk/artists-file-class-action-lawsuit-against-stability-ai-deviantart-and-midjourney). For example, the suit claims that AI art models “store com­pressed copies of \[copyright-protected\] train­ing images” and then “recombine” them; functioning as “21st-cen­tury col­lage tool\[s\].” However, AI art models do not store images at all, but rather mathematical representations of patterns collected from these images. The software does not piece together bits of images in the form of a collage, either, but creates pictures from scratch based on these mathematical representations.

_The Verge_ has reached out to Matthew Butterick, Stability AI, Midjourney, and DeviantArt for comment. We will update the story if we hear back.",AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit,https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart
"[""James Vincent""]",2023-05-19,2023-05-19,2023-01-16,2023-05-19,https://cdn.vox-cdn.com/thumbor/WIVWIM4vaf7v70ygyYgBNXlfHm8=/0x0:1366x796/1200x628/filters:focal(683x398:684x399)/cdn.vox-cdn.com/uploads/chorus_asset/file/24021977/Screenshot_2022_09_14_at_14.39.17.png,,,en,,theverge.com,"[""Anonymous""]","A trio of artists have launched a lawsuit against Stability AI and Midjourney, creators of AI art generators Stable Diffusion and Midjourney, and artist portfolio platform DeviantArt, which recently created its own AI art generator, DreamUp.

The artists — Sarah Andersen, Kelly McKernan, and Karla Ortiz — allege that these organizations have infringed the rights of “millions of artists” by training their AI tools on five billion images scraped from the web “with­out the con­sent of the orig­i­nal artists.”

The lawsuit has been filed by lawyer and typographer Matthew Butterick along with the Joseph Saveri Law Firm, which specializes in antitrust and class action cases. Butterick and Saveri are [currently suing Microsoft, GitHub, and OpenAI](https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data) in a similar case involving the AI programming model CoPilot, which is trained on lines of code collected from the web.

In a [blog post announcing the suit](https://stablediffusionlitigation.com/), Butterick describes the case as “another step toward mak­ing AI fair & eth­i­cal for every­one.” He says the capacity of AI art tools like Stable Diffusion to “flood the mar­ket with an essen­tially unlim­ited num­ber of infring­ing images will inflict per­ma­nent dam­age on the mar­ket for art and artists.”

Since AI art tools exploded in popularity over the past year, the art community has reacted strongly. While some say these tools can be helpful, much like past generations of software like Photoshop and Illustrators, many more object to the use of their work to train these money-making systems. Generative AI art models are trained on billions of images collected from the web, generally without the creators’ knowledge or consent. AI art generators can then be used to create artwork that [replicates the style of specific artists](https://waxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/).

Whether or not these systems infringe on copyright law is a [complicated question which experts say will need to be settled in the courts](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data). The creators of AI art tools generally argue that the training of this software on copyrighted data is covered (in the US at least) by [fair use doctrine](https://www.copyright.gov/fair-use/). But cases involving fair use still need to be litigated and there are numerous complicating factors when it comes to AI art generators. These include the location of organizations behind these tools (as the EU and US have subtly different legal allowances for data scraping) and the purpose of these institutions (Stable Diffusion, for example, is trained on the [LAION dataset](https://laion.ai/), which is created by a German-based research non-profit, and non-profits may be treated more favorably than regular companies in fair use cases).

The lawsuit launched by Butterick and the Joseph Saveri Law Firm has also been criticized for [containing technical inaccuracies](https://www.technollama.co.uk/artists-file-class-action-lawsuit-against-stability-ai-deviantart-and-midjourney). For example, the suit claims that AI art models “store com­pressed copies of \[copyright-protected\] train­ing images” and then “recombine” them; functioning as “21st-cen­tury col­lage tool\[s\].” However, AI art models do not store images at all, but rather mathematical representations of patterns collected from these images. The software does not piece together bits of images in the form of a collage, either, but creates pictures from scratch based on these mathematical representations.

_The Verge_ has reached out to Matthew Butterick, Stability AI, Midjourney, and DeviantArt for comment. We will update the story if we hear back.",AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit,https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart
"[""Test Author""]",2023-05-19,2023-05-19,2014-01-19,2023-05-19,,,,en,,theverge.com,"[""Anonymous""]",test text test text test text test text test text test text test text test text test text test text test text test text test text ,Test Title,https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart
"[""James Vincent""]",2023-05-19,2023-05-19,2023-01-16,2023-05-19,https://cdn.vox-cdn.com/thumbor/WIVWIM4vaf7v70ygyYgBNXlfHm8=/0x0:1366x796/1200x628/filters:focal(683x398:684x399)/cdn.vox-cdn.com/uploads/chorus_asset/file/24021977/Screenshot_2022_09_14_at_14.39.17.png,,,en,,theverge.com,"[""Anonymous""]","A trio of artists have launched a lawsuit against Stability AI and Midjourney, creators of AI art generators Stable Diffusion and Midjourney, and artist portfolio platform DeviantArt, which recently created its own AI art generator, DreamUp.

The artists — Sarah Andersen, Kelly McKernan, and Karla Ortiz — allege that these organizations have infringed the rights of “millions of artists” by training their AI tools on five billion images scraped from the web “with­out the con­sent of the orig­i­nal artists.”

The lawsuit has been filed by lawyer and typographer Matthew Butterick along with the Joseph Saveri Law Firm, which specializes in antitrust and class action cases. Butterick and Saveri are [currently suing Microsoft, GitHub, and OpenAI](https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data) in a similar case involving the AI programming model CoPilot, which is trained on lines of code collected from the web.

In a [blog post announcing the suit](https://stablediffusionlitigation.com/), Butterick describes the case as “another step toward mak­ing AI fair & eth­i­cal for every­one.” He says the capacity of AI art tools like Stable Diffusion to “flood the mar­ket with an essen­tially unlim­ited num­ber of infring­ing images will inflict per­ma­nent dam­age on the mar­ket for art and artists.”

Since AI art tools exploded in popularity over the past year, the art community has reacted strongly. While some say these tools can be helpful, much like past generations of software like Photoshop and Illustrators, many more object to the use of their work to train these money-making systems. Generative AI art models are trained on billions of images collected from the web, generally without the creators’ knowledge or consent. AI art generators can then be used to create artwork that [replicates the style of specific artists](https://waxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/).

Whether or not these systems infringe on copyright law is a [complicated question which experts say will need to be settled in the courts](https://www.theverge.com/23444685/generative-ai-copyright-infringement-legal-fair-use-training-data). The creators of AI art tools generally argue that the training of this software on copyrighted data is covered (in the US at least) by [fair use doctrine](https://www.copyright.gov/fair-use/). But cases involving fair use still need to be litigated and there are numerous complicating factors when it comes to AI art generators. These include the location of organizations behind these tools (as the EU and US have subtly different legal allowances for data scraping) and the purpose of these institutions (Stable Diffusion, for example, is trained on the [LAION dataset](https://laion.ai/), which is created by a German-based research non-profit, and non-profits may be treated more favorably than regular companies in fair use cases).

The lawsuit launched by Butterick and the Joseph Saveri Law Firm has also been criticized for [containing technical inaccuracies](https://www.technollama.co.uk/artists-file-class-action-lawsuit-against-stability-ai-deviantart-and-midjourney). For example, the suit claims that AI art models “store com­pressed copies of \[copyright-protected\] train­ing images” and then “recombine” them; functioning as “21st-cen­tury col­lage tool\[s\].” However, AI art models do not store images at all, but rather mathematical representations of patterns collected from these images. The software does not piece together bits of images in the form of a collage, either, but creates pictures from scratch based on these mathematical representations.

_The Verge_ has reached out to Matthew Butterick, Stability AI, Midjourney, and DeviantArt for comment. We will update the story if we hear back.",AI art tools Stable Diffusion and Midjourney targeted with copyright lawsuit,https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart
"[""The Spoonless Kitchen""]",2023-05-21,2023-05-21,2020-09-01,2023-05-21,,2023-05-21,,en,,twitter.com,"[""Anonymous""]","If you go through all of my Twitter account postings, back to September 1, 2020, you will see my documentation of foreign bad actors posting COVID-19 disinformation on Twitter (a small sample), as well as my responses indicating where replies threads against, in particular, Canadian federal government accounts trying to provide information about the pandemic, had their replies flooded with this campaign: https://www.bellingcat.com/news/2020/08/21/who-director-general-attacked-on-twitter-with-ccp-related-memes/

This began on September 1, 2020, with the foreign state bad actors flooding the CPHO_Canada Twitter account with ""6%"" either just that phrase, or ""only 6% of deaths are COVID"" disinformation. As I noted later (when I found a Reddit thread on same), this was a disinformation campaign based on the American numbers - which were, and remain, vastly higher than the Canadian numbers. So they got off to a very bad start, but this did not stop them. Unfortunately.

By mid-September 2020, the replies flooding the CPHO_Canada account's every scheduled tweet, began to increase in traffic to 500-1K per post. It only increased from there, as they branched out to the replies every single science communications account trying to help stop the spread of pandemic disease on Twitter.

By late 2020, the foreign state bad actors were using ""Ryan Cole"" and ""Mike Yeadon"" and ""John Campbell"" as 'sources' and 'experts' (real or imagined - Cole was actively anti-vaccination, Yeadon, a lab tech at Pfizer, was inflated to being ""VP of Pfizer"" and Campbell, a nursing instructor, was inflated to being ""Dr"" Campbell, neither of which is true), and included spamming videos promoting the spread of coronavirus and discouraging vaccination on Twitter.

This caused the Alpha variant of SARS-CoV-2 to mutate in the United Kingdom, and then spread throughout most of the Commonwealth countries.

Bolstered by this ""success"" the foreign state bad actors, in January 2021, began flooding Twitter with ""ivermectin"" disinformation at very high volumes (including posting thousands of disinformation-containing replies about the anti-parasitic as a COVID ""cure"" to each EpiTwitter, IDTwitter, and MedTwitter account posting about the pandemic) - but they were directing this disinformation mostly at the Global South, as I documented here:
https://twitter.com/TheSpoonless/status/1460728333805789190?s=20

This was the result of that disinformation campaign:
https://www.theguardian.com/news/2021/apr/28/crime-against-humanity-arundhati-roy-india-covid-catastrophe

Deaths in India were undercounted, and are actually in the range 4 million COVID deaths, NOT the ""official"" 300K deaths:
https://www.cbc.ca/news/world/india-coronavirus-counting-1.6011527

The only accurate dashboard of SARS-CoV-2 deaths remains The Economist's:
https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates

30 million deaths have been caused, and most of the deaths since 2021 have been needless, as the pandemic should have ended by then, with 90% efficacy against the non-mutated strains of the virus. Which only mutated due to these disinformation campaigns I have attempted to document a small subset of, via my Twitter account.

So this disinformation campaign aimed at the Global South caused the Delta variant of SARS-CoV-2 to escape the vaccine immunity, and prolonged the pandemic, as well as introducing a deadlier variant into the global population, and causing 10 million deaths in 2021 alone.

But this was the first prong of the two-pronged disinfodemic the foreign state bad actors caused, which I documented parts of, on my Twitter account (about 30K tweets). The second arm of the foreign state bad actors' disinformation campaign about the anti-parasitic, which also actively discouraged vaccination, and encouraged the spread of disease, began to be aimed at the United States of America, beginning in July 2021. This was largely accomplished via the ""Robert Malone"" account that maliciously posted constant disinformation, and was amplified and re-amplified and replied to, in high volumes, by the foreign state bad actors.

Even as they continued their multilingual disinformation campaigns, which I got some receipts of:

https://www.cnn.com/2021/09/08/politics/pro-chinese-disinformation-operation-coronavirus-pandemic-protests/index.html

By September 11, 2021, the 20th anniversary of 9/11 (this was NOT a coincidence), the ""ivermectin"" disinformation campaign on Twitter had hit 20,700 tweets and replies per hour, containing disinformation, encouraging spread of disease and discouraging vaccination, at the rate of 6 tweets per second. Here is my receipt of same: https://twitter.com/TheSpoonless/status/1436749753627381760

This caused the Omicron variant of SARS-CoV-2 to mutate in (and spread from) the United States:
https://web.archive.org/web/20211205160821/https://www.nytimes.com/2021/12/05/nyregion/nyc-anime-convention-omicron-cases.html

This coincided with the rolling-back and winding down of government programs to fight the pandemic near the end of 2021, which were predicated on the vaccination success rate and NO immunity escape mutations, of the population. Which clearly, was wrong, as then SARS-CoV-2 hit mammalian transmission:
https://www.nationalgeographic.com/animals/article/how-so-many-animal-species-contract-covid

So then Omicron was allowed to spread freely across the face of the earth, killing 10 million more people in 2022, not due to increased lethality (as with the Delta variant) but due to higher transmission. Which now will never be or become low transmission, because it is in every mammal reservoir on the earth. Which was when the foreign state bad actors' plan, to go ""zero COVID"" failed to stop the plague in THEIR country, even as they deliberately encouraged the spread of the plague in every OTHER country, around the world:

https://web.archive.org/web/20230208145657/https://www.cbc.ca/news/world/shanghai-china-covid-outbreak-1.6408520

I never had an option, via Twitter, to report COVID-19 disinformation directly (even though fake users constantly responded to me, saying this was an option - Twitter was lying and trying to cover itself from liability for 30M COVID deaths at that point). Also, by early 2021, as noted in my tweet documenting the beginning of the high-volume ivermectin disinformation campaign aimed at the Global South, I was already being ""rate limit exceeded"" for trying to report the Chinese trolls' disinformation campaign that has now successfully destroyed human civilization (including theirs, because they failed to comprehend how encouraging the spread would eventually tip over into COVID becoming a fully epidemic disease, spreading back and forth amongst humans who have largely ""returned to normal"" which of course reduces the efficacy of vaccines and vaccination efforts. This is also the problem with annual influenza vaccines; by the time those are fully-deployed, the influenza virus of the year has been willfully spread so much, across the face of the earth, that the current year's infection has already escaped the vaccines.

The same thing is happening with COVID, only the vaccines are not updated as frequently, and the mutations are now (possibly always have, with subvariants) occurring every 3-6 months. As with non-lethal common cold coronaviruses.

All of which has been caused by foreign state bad actor disinformation campaigns deployed via American antisocial media corporations' websites, wherein the PAYING (because China and Russia paid Twitter to allow them to do this, the ivermectin disinformation that hit 6 tweets per second on the 20th anniversary of 9/11 was a PURCHASED ""Twitter Takeover"" see page 6: https://web.archive.org/web/20230411093820/https://s22.q4cdn.com/826641620/files/doc_financials/2021/ar/FiscalYR2021_Twitter_Annual_-Report.pdf - note that Twitter has now attempted to hide this revealing piece of data, by removing the report from its website: https://s22.q4cdn.com/826641620/files/doc_financials/2021/ar/FiscalYR2021_Twitter_Annual_-Report.pdf - alternate link, if Twitter requests removal from the Library of Congress Archive: https://ln5.sync.com/dl/99f2778d0/dpevxwwz-35kjva7r-g2zxgqqi-rr7c38xe).

Further documentation on how I was deliberately ""rate limit exceeded"" by Twitter when I attempted to report the COVID-19 disinformation-spreading accounts as ""suspicious or spam"" - because, again, I had NO option to report COVID-19 disinformation, despite being informed, wrongly, repeatedly, that was how I should be filing):

https://www.reddit.com/r/Qult_Headquarters/comments/yl4nwe/comment/iuwnm83/

From January 28, 2022, until November 13, 2022, my account was unjustly suspended from Twitter, for posting screenshots of COVID-19 disinformation/foreign state bad actors (who were attacking, via the replies, WITH PAID ADVERTISING, which I screenshot, the Canadian National Institute of Ageing and Ryerson University's tweet about their COVID-19 Risk Assessment tool). This suspension was only reversed, once I sent the above receipts to Alex E. Heath of The Verge - HOWEVER, Twitter did NOT acknowledge its role in the harms of the pandemic, simply LYING and saying my account was wrongly suspended by ""automatic"" processes.

These processes were NOT ""automatic"" they were TRIGGERED deliberately by foreign state bad actors to censor my freedom of expression on the Internet:

https://twitter.com/TheSpoonless/status/1441967952471990273?s=20

Let me state, clearly, what is going on here: I am NOT an American citizen, nor do I reside in the United States of America, yet, for three years, an AMERICAN corporation has restricted and/or censored my freedom of expression (which violates the charter of human rights of the country I am a citizen of) ON THE INTERNET.

Which has also caused a SECOND non-ending pandemic of plague across the face of the earth. To which I am still susceptible. Despite being nearly fully-vaccinated (next shot coming up soon). The first one being influenza, which became a non-ending 105-year-old pandemic, during a time there were NO vaccines, and there was NO ability to stop spread. 

105 years later, there were effective vaccines, and an effective ability to disseminate information stop the spread - until this effective ability was turned towards deliberately CAUSING the spread of severe acute respirator syndrome coronavirus 2, which is exactly what Twitter did. Slight problem with this? Influenza has caused 42 million deaths, over 105 years.

COVID-19 has caused 30 million deaths over ONLY 3-1/2 years.

So you see the issue here? Twitter helped to cause this, and I have proof Twitter helped to cause this, and if you go back through every single one of my 30K+ tweets documenting this, you can see the receipts of how Twitter helped to cause this.

As Twitter continues to hide and cover up and attempt to deny responsibility for what it has done.",SARS-CoV-2 Pandemic extended and made endemic by foreign state bad actors encouraging willful spread of disease to foster mutations,https://www.twitter.com/TheSpoonless
"[""The Spoonless Kitchen""]",2023-05-21,2023-05-21,2020-09-01,2023-05-21,,2023-05-21,,en,,twitter.com,"[""Anonymous""]","If you go through all of my Twitter account postings, back to September 1, 2020, you will see my documentation of foreign bad actors posting COVID-19 disinformation on Twitter (a small sample), as well as my responses indicating where replies threads against, in particular, Canadian federal government accounts trying to provide information about the pandemic, had their replies flooded with this campaign: https://www.bellingcat.com/news/2020/08/21/who-director-general-attacked-on-twitter-with-ccp-related-memes/

This began on September 1, 2020, with the foreign state bad actors flooding the CPHO_Canada Twitter account with ""6%"" either just that phrase, or ""only 6% of deaths are COVID"" disinformation. As I noted later (when I found a Reddit thread on same), this was a disinformation campaign based on the American numbers - which were, and remain, vastly higher than the Canadian numbers. So they got off to a very bad start, but this did not stop them. Unfortunately.

By mid-September 2020, the replies flooding the CPHO_Canada account's every scheduled tweet, began to increase in traffic to 500-1K per post. It only increased from there, as they branched out to the replies every single science communications account trying to help stop the spread of pandemic disease on Twitter.

By late 2020, the foreign state bad actors were using ""Ryan Cole"" and ""Mike Yeadon"" and ""John Campbell"" as 'sources' and 'experts' (real or imagined - Cole was actively anti-vaccination, Yeadon, a lab tech at Pfizer, was inflated to being ""VP of Pfizer"" and Campbell, a nursing instructor, was inflated to being ""Dr"" Campbell, neither of which is true), and included spamming videos promoting the spread of coronavirus and discouraging vaccination on Twitter.

This caused the Alpha variant of SARS-CoV-2 to mutate in the United Kingdom, and then spread throughout most of the Commonwealth countries.

Bolstered by this ""success"" the foreign state bad actors, in January 2021, began flooding Twitter with ""ivermectin"" disinformation at very high volumes (including posting thousands of disinformation-containing replies about the anti-parasitic as a COVID ""cure"" to each EpiTwitter, IDTwitter, and MedTwitter account posting about the pandemic) - but they were directing this disinformation mostly at the Global South, as I documented here:
https://twitter.com/TheSpoonless/status/1460728333805789190?s=20

This was the result of that disinformation campaign:
https://www.theguardian.com/news/2021/apr/28/crime-against-humanity-arundhati-roy-india-covid-catastrophe

Deaths in India were undercounted, and are actually in the range 4 million COVID deaths, NOT the ""official"" 300K deaths:
https://www.cbc.ca/news/world/india-coronavirus-counting-1.6011527

The only accurate dashboard of SARS-CoV-2 deaths remains The Economist's:
https://www.economist.com/graphic-detail/coronavirus-excess-deaths-estimates

30 million deaths have been caused, and most of the deaths since 2021 have been needless, as the pandemic should have ended by then, with 90% efficacy against the non-mutated strains of the virus. Which only mutated due to these disinformation campaigns I have attempted to document a small subset of, via my Twitter account.

So this disinformation campaign aimed at the Global South caused the Delta variant of SARS-CoV-2 to escape the vaccine immunity, and prolonged the pandemic, as well as introducing a deadlier variant into the global population, and causing 10 million deaths in 2021 alone.

But this was the first prong of the two-pronged disinfodemic the foreign state bad actors caused, which I documented parts of, on my Twitter account (about 30K tweets). The second arm of the foreign state bad actors' disinformation campaign about the anti-parasitic, which also actively discouraged vaccination, and encouraged the spread of disease, began to be aimed at the United States of America, beginning in July 2021. This was largely accomplished via the ""Robert Malone"" account that maliciously posted constant disinformation, and was amplified and re-amplified and replied to, in high volumes, by the foreign state bad actors.

Even as they continued their multilingual disinformation campaigns, which I got some receipts of:

https://www.cnn.com/2021/09/08/politics/pro-chinese-disinformation-operation-coronavirus-pandemic-protests/index.html

By September 11, 2021, the 20th anniversary of 9/11 (this was NOT a coincidence), the ""ivermectin"" disinformation campaign on Twitter had hit 20,700 tweets and replies per hour, containing disinformation, encouraging spread of disease and discouraging vaccination, at the rate of 6 tweets per second. Here is my receipt of same: https://twitter.com/TheSpoonless/status/1436749753627381760

This caused the Omicron variant of SARS-CoV-2 to mutate in (and spread from) the United States:
https://web.archive.org/web/20211205160821/https://www.nytimes.com/2021/12/05/nyregion/nyc-anime-convention-omicron-cases.html

This coincided with the rolling-back and winding down of government programs to fight the pandemic near the end of 2021, which were predicated on the vaccination success rate and NO immunity escape mutations, of the population. Which clearly, was wrong, as then SARS-CoV-2 hit mammalian transmission:
https://www.nationalgeographic.com/animals/article/how-so-many-animal-species-contract-covid

So then Omicron was allowed to spread freely across the face of the earth, killing 10 million more people in 2022, not due to increased lethality (as with the Delta variant) but due to higher transmission. Which now will never be or become low transmission, because it is in every mammal reservoir on the earth. Which was when the foreign state bad actors' plan, to go ""zero COVID"" failed to stop the plague in THEIR country, even as they deliberately encouraged the spread of the plague in every OTHER country, around the world:

https://web.archive.org/web/20230208145657/https://www.cbc.ca/news/world/shanghai-china-covid-outbreak-1.6408520

I never had an option, via Twitter, to report COVID-19 disinformation directly (even though fake users constantly responded to me, saying this was an option - Twitter was lying and trying to cover itself from liability for 30M COVID deaths at that point). Also, by early 2021, as noted in my tweet documenting the beginning of the high-volume ivermectin disinformation campaign aimed at the Global South, I was already being ""rate limit exceeded"" for trying to report the Chinese trolls' disinformation campaign that has now successfully destroyed human civilization (including theirs, because they failed to comprehend how encouraging the spread would eventually tip over into COVID becoming a fully epidemic disease, spreading back and forth amongst humans who have largely ""returned to normal"" which of course reduces the efficacy of vaccines and vaccination efforts. This is also the problem with annual influenza vaccines; by the time those are fully-deployed, the influenza virus of the year has been willfully spread so much, across the face of the earth, that the current year's infection has already escaped the vaccines.

The same thing is happening with COVID, only the vaccines are not updated as frequently, and the mutations are now (possibly always have, with subvariants) occurring every 3-6 months. As with non-lethal common cold coronaviruses.

All of which has been caused by foreign state bad actor disinformation campaigns deployed via American antisocial media corporations' websites, wherein the PAYING (because China and Russia paid Twitter to allow them to do this, the ivermectin disinformation that hit 6 tweets per second on the 20th anniversary of 9/11 was a PURCHASED ""Twitter Takeover"" see page 6: https://web.archive.org/web/20230411093820/https://s22.q4cdn.com/826641620/files/doc_financials/2021/ar/FiscalYR2021_Twitter_Annual_-Report.pdf - note that Twitter has now attempted to hide this revealing piece of data, by removing the report from its website: https://s22.q4cdn.com/826641620/files/doc_financials/2021/ar/FiscalYR2021_Twitter_Annual_-Report.pdf - alternate link, if Twitter requests removal from the Library of Congress Archive: https://ln5.sync.com/dl/99f2778d0/dpevxwwz-35kjva7r-g2zxgqqi-rr7c38xe).

Further documentation on how I was deliberately ""rate limit exceeded"" by Twitter when I attempted to report the COVID-19 disinformation-spreading accounts as ""suspicious or spam"" - because, again, I had NO option to report COVID-19 disinformation, despite being informed, wrongly, repeatedly, that was how I should be filing):

https://www.reddit.com/r/Qult_Headquarters/comments/yl4nwe/comment/iuwnm83/

From January 28, 2022, until November 13, 2022, my account was unjustly suspended from Twitter, for posting screenshots of COVID-19 disinformation/foreign state bad actors (who were attacking, via the replies, WITH PAID ADVERTISING, which I screenshot, the Canadian National Institute of Ageing and Ryerson University's tweet about their COVID-19 Risk Assessment tool). This suspension was only reversed, once I sent the above receipts to Alex E. Heath of The Verge - HOWEVER, Twitter did NOT acknowledge its role in the harms of the pandemic, simply LYING and saying my account was wrongly suspended by ""automatic"" processes.

These processes were NOT ""automatic"" they were TRIGGERED deliberately by foreign state bad actors to censor my freedom of expression on the Internet:

https://twitter.com/TheSpoonless/status/1441967952471990273?s=20

Let me state, clearly, what is going on here: I am NOT an American citizen, nor do I reside in the United States of America, yet, for three years, an AMERICAN corporation has restricted and/or censored my freedom of expression (which violates the charter of human rights of the country I am a citizen of) ON THE INTERNET.

Which has also caused a SECOND non-ending pandemic of plague across the face of the earth. To which I am still susceptible. Despite being nearly fully-vaccinated (next shot coming up soon). The first one being influenza, which became a non-ending 105-year-old pandemic, during a time there were NO vaccines, and there was NO ability to stop spread. 

105 years later, there were effective vaccines, and an effective ability to disseminate information stop the spread - until this effective ability was turned towards deliberately CAUSING the spread of severe acute respirator syndrome coronavirus 2, which is exactly what Twitter did. Slight problem with this? Influenza has caused 42 million deaths, over 105 years.

COVID-19 has caused 30 million deaths over ONLY 3-1/2 years.

So you see the issue here? Twitter helped to cause this, and I have proof Twitter helped to cause this, and if you go back through every single one of my 30K+ tweets documenting this, you can see the receipts of how Twitter helped to cause this.

As Twitter continues to hide and cover up and attempt to deny responsibility for what it has done.",SARS-CoV-2 Pandemic extended and made endemic by foreign state bad actors encouraging willful spread of disease to foster mutations,http://www.twitter.com/TheSpoonless
"[""The Spoonless Kitchen""]",2023-05-21,2023-05-21,2020-09-01,2023-05-21,https://nitter.net/pic/pbs.twimg.com%2Fprofile_images%2F1441177299534049291%2FU35UYDz-_400x400.jpg,2023-05-21,,en,,nitter.net,"[""Anonymous""]","And here's a screenshot proving this tweet got 397 views - ooooh that must burn, Yoo Suk! Even though the original tweet I am quote tweeting, that had hundreds more views now says ""Something Went Wrong"".....

[](/pic/orig/media%2FFv70SRMXoAI8fQ9.jpg)

[Show this thread](/i/status/1623829925579878403)",The Spoonless Kitchen epicure.social/@thespoonless (@TheSpoonless),https://nitter.net/TheSpoonless
